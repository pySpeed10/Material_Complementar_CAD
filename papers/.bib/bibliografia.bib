
@article{sounderajah_developing_2021,
	title = {Developing a reporting guideline for artificial intelligence-centred diagnostic test accuracy studies: {The} {STARD}-{AI} protocol},
	volume = {11},
	doi = {10.1136/bmjopen-2020-047709},
	number = {6},
	journal = {BMJ Open},
	author = {Sounderajah, Viknesh and Ashrafian, Hutan and Rose, Sam and Shah, Anjali and Ghassemi, Marzyeh and Golub, Robert and Moons, Karel GM and Bossuyt, Patrick M and Darzi, Ara and Denniston, Alastair K},
	year = {2021},
	note = {Publisher: BMJ Publishing Group},
	pages = {e047709},
}

@article{whiting_quadas-2_2011,
	title = {{QUADAS}-2: a revised tool for the quality assessment of diagnostic accuracy studies},
	volume = {155},
	doi = {10.7326/0003-4819-155-8-201110180-00009},
	number = {8},
	journal = {Annals of internal medicine},
	author = {Whiting, Penny F and Rutjes, Anne WG and Westwood, Marie E and Mallett, Sue and Deeks, Jonathan J and Reitsma, Johannes B and Leeflang, Mariska MG and Sterne, Jonathan AC and Bossuyt, Patrick MM},
	year = {2011},
	note = {Publisher: American College of Physicians},
	pages = {529--536},
}

@article{samek_explainable_2017,
	title = {Explainable artificial intelligence: {Understanding}, visualizing and interpreting deep learning models},
	journal = {arXiv preprint arXiv:1708.08296},
	author = {Samek, Wojciech and Wiegand, Thomas and Müller, Klaus-Robert},
	year = {2017},
}

@article{armstrong_reporting_2019,
	title = {Reporting of artificial intelligence prediction models},
	volume = {365},
	doi = {10.1136/bmj.l1265},
	journal = {BMJ},
	author = {Armstrong, Sonya and Tsao, Philip S and Sun, Pei Pei and Mandl, Kenneth D},
	year = {2019},
	pages = {l1265},
}

@article{litjens_survey_2017,
	title = {A survey on deep learning in medical image analysis},
	volume = {42},
	doi = {10.1016/j.media.2017.07.005},
	journal = {Medical image analysis},
	author = {Litjens, Geert and Kooi, Thijs and Bejnordi, Babak Ehteshami and Setio, Arnaud Arindra Adiyoso and Ciompi, Francesco and Ghafoorian, Mohsen and van der Laak, Jeroen AWM and van Ginneken, Bram and Sánchez, Clara I},
	year = {2017},
	note = {Publisher: Elsevier},
	pages = {60--88},
}

@article{esteva_guide_2019,
	title = {A guide to deep learning in healthcare},
	volume = {25},
	doi = {10.1038/s41591-018-0316-z},
	number = {1},
	journal = {Nature Medicine},
	author = {Esteva, Andre and Robicquet, Alexandre and Ramsundar, Bharath and Kuleshov, Volodymyr and DePristo, Mark and Chou, Katherine and Cui, Claire and Corrado, Greg and Thrun, Sebastian and Dean, Jeff},
	year = {2019},
	note = {Publisher: Nature Publishing Group},
	pages = {24--29},
}

@article{liu_delving_2019,
	title = {Delving into the interpretability of deep learning models for medical image analysis},
	volume = {104},
	doi = {10.1136/bjophthalmol-2019-314155},
	number = {4},
	journal = {The British Journal of Ophthalmology},
	author = {Liu, Xiaoxuan and Faes, Livia and Kale, Ajay U and Wagner, Simon K and Fu, David J and Bruynseels, Aditya and Mahendiran, Thushyanthan and Moraes, Gabriella and Shamdas, Marcus and Kern, Caroline and {others}},
	year = {2019},
	note = {Publisher: BMJ Publishing Group},
	pages = {441--446},
}

@article{pineau_improving_2021,
	title = {Improving reproducibility in machine learning research (a report from the {NeurIPS} 2019 reproducibility program)},
	volume = {22},
	number = {1},
	journal = {Journal of Machine Learning Research},
	author = {Pineau, Joelle and Vincent-Lamarre, Philippe and Sinha, Koustuv and Larivière, Vincent and Beygelzimer, Alina and d’Alché-Buc, Florence and Fox, Emily and Larochelle, Hugo},
	year = {2021},
	note = {Publisher: JMLR. org},
	pages = {1--20},
}

@article{banumathy_cad_2022,
	title = {{CAD} of {BCD} from {Thermal} {Mammogram} {Images} {Using} {Machine} {Learning}},
	volume = {34},
	issn = {1079-8587},
	url = {https://www.techscience.com/iasc/v34n1/47370},
	doi = {10.32604/iasc.2022.025609},
	language = {en},
	number = {1},
	urldate = {2025-05-16},
	journal = {Intelligent Automation \& Soft Computing},
	author = {Banumathy, D. and Ibrahim Khalaf, Osamah and Andr Tavera Romero, Carlos and Indra, J. and Kumar Sharma, Dilip},
	year = {2022},
	pages = {667--685},
	file = {Texto completo:C\:\\Users\\Wellerson\\Zotero\\storage\\73ZE6PDZ\\Banumathy et al. - 2022 - CAD of BCD from Thermal Mammogram Images Using Machine Learning.pdf:application/pdf},
}

@article{dillshad_d2lfs2net_2025,
	title = {{D2LFS2Net}: {Multi}‐class skin lesion diagnosis using deep learning and variance‐controlled {Marine} {Predator} optimisation: {An} application for precision medicine},
	volume = {10},
	issn = {2468-2322, 2468-2322},
	shorttitle = {{D2LFS2Net}},
	url = {https://ietresearch.onlinelibrary.wiley.com/doi/10.1049/cit2.12267},
	doi = {10.1049/cit2.12267},
	abstract = {Abstract In computer vision applications like surveillance and remote sensing, to mention a few, deep learning has had considerable success. Medical imaging still faces a number of difficulties, including intra‐class similarity, a scarcity of training data, and poor contrast skin lesions, notably in the case of skin cancer. An optimisation‐aided deep learning‐based system is proposed for accurate multi‐class skin lesion identification. The sequential procedures of the proposed system start with preprocessing and end with categorisation. The preprocessing step is where a hybrid contrast enhancement technique is initially proposed for lesion identification with healthy regions. Instead of flipping and rotating data, the outputs from the middle phases of the hybrid enhanced technique are employed for data augmentation in the next step. Next, two pre‐trained deep learning models, MobileNetV2 and NasNet Mobile, are trained using deep transfer learning on the upgraded enriched dataset. Later, a dual‐threshold serial approach is employed to obtain and combine the features of both models. The next step was the variance‐controlled Marine Predator methodology, which the authors proposed as a superior optimisation method. The top features from the fused feature vector are classified using machine learning classifiers. The experimental strategy provided enhanced accuracy of 94.4\% using the publicly available dataset HAM10000. Additionally, the proposed framework is evaluated compared to current approaches, with remarkable results.},
	language = {en},
	number = {1},
	urldate = {2025-05-16},
	journal = {CAAI Transactions on Intelligence Technology},
	author = {Dillshad, Veena and Khan, Muhammad Attique and Nazir, Muhammad and Saidani, Oumaima and Alturki, Nazik and Kadry, Seifedine},
	month = feb,
	year = {2025},
	pages = {207--222},
}

@article{chharia_deep-precognitive_2022,
	title = {Deep-{Precognitive} {Diagnosis}: {Preventing} {Future} {Pandemics} by {Novel} {Disease} {Detection} {With} {Biologically}-{Inspired} {Conv}-{Fuzzy} {Network}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	shorttitle = {Deep-{Precognitive} {Diagnosis}},
	url = {https://ieeexplore.ieee.org/document/9718075/},
	doi = {10.1109/ACCESS.2022.3153059},
	urldate = {2025-05-16},
	journal = {IEEE Access},
	author = {Chharia, Aviral and Upadhyay, Rahul and Kumar, Vinay and Cheng, Chao and Zhang, Jing and Wang, Tianyang and Xu, Min},
	year = {2022},
	pages = {23167--23185},
	file = {Texto completo:C\:\\Users\\Wellerson\\Zotero\\storage\\773RK4YE\\Chharia et al. - 2022 - Deep-Precognitive Diagnosis Preventing Future Pandemics by Novel Disease Detection With Biologicall.pdf:application/pdf},
}

@article{thamer_detection_2022,
	title = {Detection of {Covid}-19 {Using} {CAD} {System} {Depending} on {Chest} {X}-{Ray} and {Machine} {Learning} {Techniques}},
	volume = {18},
	issn = {2078-6069, 1814-5892},
	url = {https://ijeee.edu.iq/Papers/Vol18-Issue2/1570810165.pdf},
	doi = {10.37917/ijeee.18.2.10},
	abstract = {SARS-COV-2 (severe acute respiratory syndrome coronavirus-2) has caused widespread mortality. Infected individuals had specific radiographic visual features and fever, dry cough, lethargy, dyspnea, and other symptoms. According to the study, the chest X-ray (CXR) is one of the essential non-invasive clinical adjuncts for detecting such visual reactions associated with SARS-COV-2. Manual diagnosis is hindered by a lack of radiologists’ availability to interpret CXR images and by the faint appearance of illness radiographic responses. The paper describes an automatic COVID detection based on the deep learning-based system that applied transfer learning techniques to extract features from CXR images to distinguish. The system has three main components. The first part is extracting CXR features with MobileNetV2. The second part used the extracted features and applied Dimensionality reduction using LDA. The final part is a Classifier, which employed XGBoost to classify dataset images into Normal, Pneumonia, and Covid-19. The proposed system achieved both immediate and high results with an overall accuracy of 0.96\%, precision of 0.95\%, recall of 0.94\%, and F1 score of 0.94\%.},
	language = {en},
	number = {2},
	urldate = {2025-05-16},
	journal = {Iraqi Journal for Electrical and Electronic Engineering},
	author = {Thamer, Sadeer and Alshmmri, Mshari},
	month = dec,
	year = {2022},
	pages = {75--81},
	file = {Texto completo:C\:\\Users\\Wellerson\\Zotero\\storage\\U2XAWQGC\\Thamer e Alshmmri - 2022 - Detection of Covid-19 Using CAD System Depending on Chest X-Ray and Machine Learning Techniques.pdf:application/pdf},
}

@inproceedings{qjidaa_development_2020,
	address = {Fez, Morocco},
	title = {Development of a clinical decision support system for the early detection of {COVID}-19 using deep learning based on chest radiographic images},
	copyright = {https://ieeexplore.ieee.org/Xplorehelp/downloads/license-information/IEEE.html},
	isbn = {978-1-7281-8041-0},
	url = {https://ieeexplore.ieee.org/document/9204282/},
	doi = {10.1109/ISCV49265.2020.9204282},
	urldate = {2025-05-16},
	booktitle = {2020 {International} {Conference} on {Intelligent} {Systems} and {Computer} {Vision} ({ISCV})},
	publisher = {IEEE},
	author = {Qjidaa, M. and Ben-fares, A. and Mechbal, Y. and Amakdouf, H. and Maaroufi, M. and Alami, B. and Qjidaa, H.},
	month = jun,
	year = {2020},
	pages = {1--6},
}

@article{panteris_machine_2022,
	title = {Machine {Learning} {Algorithm} to {Predict} {Obstructive} {Coronary} {Artery} {Disease}: {Insights} from the {CorLipid} {Trial}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2218-1989},
	shorttitle = {Machine {Learning} {Algorithm} to {Predict} {Obstructive} {Coronary} {Artery} {Disease}},
	url = {https://www.mdpi.com/2218-1989/12/9/816},
	doi = {10.3390/metabo12090816},
	abstract = {Developing risk assessment tools for CAD prediction remains challenging nowadays. We developed an ML predictive algorithm based on metabolic and clinical data for determining the severity of CAD, as assessed via the SYNTAX score. Analytical methods were developed to determine serum blood levels of specific ceramides, acyl-carnitines, fatty acids, and proteins such as galectin-3, adiponectin, and APOB/APOA1 ratio. Patients were grouped into: obstructive CAD (SS {\textbackslash}textgreater 0) and non-obstructive CAD (SS = 0). A risk prediction algorithm (boosted ensemble algorithm XGBoost) was developed by combining clinical characteristics with established and novel biomarkers to identify patients at high risk for complex CAD. The study population comprised 958 patients (CorLipid trial (NCT04580173)), with no prior CAD, who underwent coronary angiography. Of them, 533 (55.6\%) suffered ACS, 170 (17.7\%) presented with NSTEMI, 222 (23.2\%) with STEMI, and 141 (14.7\%) with unstable angina. Of the total sample, 681 (71\%) had obstructive CAD. The algorithm dataset was 73 biochemical parameters and metabolic biomarkers as well as anthropometric and medical history variables. The performance of the XGBoost algorithm had an AUC value of 0.725 (95\% CI: 0.691–0.759). Thus, a ML model incorporating clinical features in addition to certain metabolic features can estimate the pre-test likelihood of obstructive CAD.},
	language = {en},
	number = {9},
	urldate = {2025-05-16},
	journal = {Metabolites},
	author = {Panteris, Eleftherios and Deda, Olga and Papazoglou, Andreas S. and Karagiannidis, Efstratios and Liapikos, Theodoros and Begou, Olga and Meikopoulos, Thomas and Mouskeftara, Thomai and Sofidis, Georgios and Sianos, Georgios and Theodoridis, Georgios and Gika, Helen},
	month = aug,
	year = {2022},
	pages = {816},
	file = {Texto completo:C\:\\Users\\Wellerson\\Zotero\\storage\\RJD75GMJ\\Panteris et al. - 2022 - Machine Learning Algorithm to Predict Obstructive Coronary Artery Disease Insights from the CorLipi.pdf:application/pdf},
}

@article{yu_machine_2023,
	title = {Machine learning to predict hemodynamically significant {CAD} based on traditional risk factors, coronary artery calcium and epicardial fat volume},
	volume = {30},
	issn = {10713581},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1071358124002022},
	doi = {10.1007/s12350-023-03333-0},
	language = {en},
	number = {6},
	urldate = {2025-05-16},
	journal = {Journal of Nuclear Cardiology},
	author = {Yu, Wenji and Yang, Le and Zhang, Feifei and Liu, Bao and Shi, Yunmei and Wang, Jianfeng and Shao, Xiaoliang and Chen, Yongjun and Yang, Xiaoyu and Wang, Yuetao},
	month = dec,
	year = {2023},
	pages = {2593--2606},
}

@article{hua_microfluidics-based_2024,
	title = {Microfluidics-based patient-derived disease detection tool for deep learning-assisted precision medicine},
	volume = {18},
	issn = {1932-1058},
	url = {https://pubs.aip.org/bmf/article/18/1/014101/2933755/Microfluidics-based-patient-derived-disease},
	doi = {10.1063/5.0172146},
	abstract = {Cancer spatial and temporal heterogeneity fuels resistance to therapies. To realize the routine assessment of cancer prognosis and treatment, we demonstrate the development of an Intelligent Disease Detection Tool (IDDT), a microfluidic-based tumor model integrated with deep learning-assisted algorithmic analysis. IDDT was clinically validated with liquid blood biopsy samples (n = 71) from patients with various types of cancers (e.g., breast, gastric, and lung cancer) and healthy donors, requiring low sample volume (∼200 μl) and a high-throughput 3D tumor culturing system (∼300 tumor clusters). To support automated algorithmic analysis, intelligent decision-making, and precise segmentation, we designed and developed an integrative deep neural network, which includes Mask Region-Based Convolutional Neural Network (Mask R-CNN), vision transformer, and Segment Anything Model (SAM). Our approach significantly reduces the manual labeling time by up to 90\% with a high mean Intersection Over Union (mIoU) of 0.902 and immediate results (\&lt;2 s per image) for clinical cohort classification. The IDDT can accurately stratify healthy donors (n = 12) and cancer patients (n = 55) within their respective treatment cycle and cancer stage, resulting in high precision (∼99.3\%) and high sensitivity (∼98\%). We envision that our patient-centric IDDT provides an intelligent, label-free, and cost-effective approach to help clinicians make precise medical decisions and tailor treatment strategies for each patient.},
	language = {en},
	number = {1},
	urldate = {2025-05-16},
	journal = {Biomicrofluidics},
	author = {Hua, Haojun and Zhou, Yunlan and Li, Wei and Zhang, Jing and Deng, Yanlin and Khoo, Bee Luan},
	month = jan,
	year = {2024},
	pages = {014101},
}

@article{azam_optimizing_2024,
	title = {Optimizing {Vertebral} {Lesion} {Diagnosis}: {A} {CAD}-{Driven} {Machine} {Learning} {Classification} {System} {With} {Multi}-{Modal} {MRI} {Texture} {Analysis}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	shorttitle = {Optimizing {Vertebral} {Lesion} {Diagnosis}},
	url = {https://ieeexplore.ieee.org/document/10669551/},
	doi = {10.1109/ACCESS.2024.3456630},
	urldate = {2025-05-16},
	journal = {IEEE Access},
	author = {Azam, Mohamed T. and Balaha, Hossam Magdy and Hassan, Asmaa and Alksas, Ahmed and Shehata, Mohamed and El-Morsy, Ahmed and Awad, Basem I. and Alghamdi, Norah Saleh and Ghazal, Mohammed and El-Baz, Ayman},
	year = {2024},
	pages = {127846--127861},
	file = {Full Text PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\L24YA9A4\\Azam et al. - 2024 - Optimizing Vertebral Lesion Diagnosis A CAD-Driven Machine Learning Classification System With Mult.pdf:application/pdf},
}

@article{abu_precision_2025,
	title = {Precision {Medicine} {Assessment} of the {Radiographic} {Defect} {Angle} of the {Intrabony} {Defect} in {Periodontal} {Lesions} by {Deep} {Learning} of {Bitewing} {Radiographs}},
	volume = {12},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2306-5354},
	url = {https://www.mdpi.com/2306-5354/12/1/43},
	doi = {10.3390/bioengineering12010043},
	abstract = {In dental diagnosis, evaluating the severity of periodontal disease by analyzing the radiographic defect angle of the intrabony defect is essential for effective treatment planning. However, dentists often rely on clinical examinations and manual analysis, which can be time-consuming and labor-intensive. Due to the high recurrence rate of periodontal disease after treatment, accurately evaluating the radiographic defect angle of the intrabony defect is vital for implementing targeted interventions, which can improve treatment outcomes and reduce recurrence. This study aims to streamline clinical practices and enhance patient care in managing periodontal disease by determining its severity based on the analysis of the radiographic defect angle of the intrabony defect. In this approach, radiographic defect angles of the intrabony defect greater than 37 degrees are classified as severe, while those less than 37 degrees are considered mild. This study employed a series of novel image enhancement techniques to significantly improve diagnostic accuracy. Before enhancement, the maximum accuracy was 78.85\%, which increased to 95.12\% following enhancement. YOLOv8 detects the affected tooth, and its mAP can reach 95.5\%, with a precision reach of 94.32\%. This approach assists dentists in swiftly assessing the extent of periodontal erosion, enabling timely and appropriate treatment. These techniques reduce diagnostic time and improve healthcare quality.},
	language = {en},
	number = {1},
	urldate = {2025-05-16},
	journal = {Bioengineering},
	author = {Abu, Patricia Angela R. and Mao, Yi-Cheng and Lin, Yuan-Jin and Chao, Chien-Kai and Lin, Yi-He and Wang, Bo-Siang and Chen, Chiung-An and Chen, Shih-Lun and Chen, Tsung-Yi and Li, Kuo-Chen},
	month = jan,
	year = {2025},
	pages = {43},
	file = {Full Text PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\7UPQBRQ6\\Abu et al. - 2025 - Precision Medicine Assessment of the Radiographic Defect Angle of the Intrabony Defect in Periodonta.pdf:application/pdf},
}

@article{dai_risk_2023,
	title = {Risk factors for high {CAD}-{RADS} scoring in {CAD} patients revealed by machine learning methods: a retrospective study},
	volume = {11},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2167-8359},
	shorttitle = {Risk factors for high {CAD}-{RADS} scoring in {CAD} patients revealed by machine learning methods},
	url = {https://peerj.com/articles/15797},
	doi = {10.7717/peerj.15797},
	abstract = {Objective This study aimed to investigate a variety of machine learning (ML) methods to predict the association between cardiovascular risk factors and coronary artery disease-reporting and data system (CAD-RADS) scores. Methods This is a retrospective cohort study. Demographical, cardiovascular risk factors and coronary CT angiography (CCTA) characteristics of the patients were obtained. Coronary artery disease (CAD) was evaluated using CAD-RADS score. The stenosis severity component of the CAD-RADS was stratified into two groups: CAD-RADS score 0-2 group and CAD-RADS score 3–5 group. CAD-RADS scores were predicted with random forest (RF), k-nearest neighbors (KNN), support vector machines (SVM), neural network (NN), decision tree classification (DTC) and linear discriminant analysis (LDA). Prediction sensitivity, specificity, accuracy and area under the curve (AUC) were calculated. Feature importance analysis was utilized to find the most important predictors. Results A total of 442 CAD patients with CCTA examinations were included in this study. 234 (52.9\%) subjects were CAD-RADS score 0–2 group and 208 (47.1\%) were CAD-RADS score 3–5 group. CAD-RADS score 3-5 group had a high prevalence of hypertension (66.8\%), hyperlipidemia (50\%) and diabetes mellitus (DM) (35.1\%). Age, systolic blood pressure (SBP), mean arterial pressure, pulse pressure, pulse pressure index, plasma fibrinogen, uric acid and blood urea nitrogen were significantly higher ( p {\textbackslash}textless 0.001), and high-density lipoprotein (HDL-C) lower ( p {\textbackslash}textless 0.001) in CAD-RADS score 3–5 group compared to the CAD-RADS score 0–2 group. Nineteen features were chosen to train the models. RF (AUC = 0.832) and LDA (AUC = 0.81) outperformed SVM (AUC = 0.772), NN (AUC = 0.773), DTC (AUC = 0.682), KNN (AUC = 0.707). Feature importance analysis indicated that plasma fibrinogen, age and DM contributed most to CAD-RADS scores. Conclusion ML algorithms are capable of predicting the correlation between cardiovascular risk factors and CAD-RADS scores with high accuracy.},
	language = {en},
	urldate = {2025-05-16},
	journal = {PeerJ},
	author = {Dai, Yueli and Ouyang, Chenyu and Luo, Guanghua and Cao, Yi and Peng, Jianchun and Gao, Anbo and Zhou, Hong},
	month = aug,
	year = {2023},
	pages = {e15797},
	file = {Full Text PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\BVFM2F74\\Dai et al. - 2023 - Risk factors for high CAD-RADS scoring in CAD patients revealed by machine learning methods a retro.pdf:application/pdf},
}

@article{chen_skin_2022,
	title = {Skin {Lesion} {Segmentation} {Using} {Recurrent} {Attentional} {Convolutional} {Networks}},
	volume = {10},
	copyright = {https://creativecommons.org/licenses/by-nc-nd/4.0/},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9877802/},
	doi = {10.1109/ACCESS.2022.3204280},
	urldate = {2025-05-16},
	journal = {IEEE Access},
	author = {Chen, Peng and Huang, Sa and Yue, Qing},
	year = {2022},
	pages = {94007--94018},
	file = {Full Text PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\X9W5MU6E\\Chen et al. - 2022 - Skin Lesion Segmentation Using Recurrent Attentional Convolutional Networks.pdf:application/pdf},
}

@article{pattanaik_unsupervised_2020,
	title = {Unsupervised {Deep} {Learning} {CAD} {Scheme} for the {Detection} of {Malaria} in {Blood} {Smear} {Microscopic} {Images}},
	volume = {8},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9097238/},
	doi = {10.1109/ACCESS.2020.2996022},
	urldate = {2025-05-16},
	journal = {IEEE Access},
	author = {Pattanaik, Priyadarshini Adyasha and Mittal, Mohit and Khan, Mohammad Zubair},
	year = {2020},
	pages = {94936--94946},
	file = {Texto completo:C\:\\Users\\Wellerson\\Zotero\\storage\\6IVPN6BZ\\Pattanaik et al. - 2020 - Unsupervised Deep Learning CAD Scheme for the Detection of Malaria in Blood Smear Microscopic Images.pdf:application/pdf},
}

@article{mehrabi_survey_2021,
	title = {A survey on bias and fairness in machine learning},
	volume = {54},
	doi = {10.1145/3457607},
	number = {6},
	journal = {ACM Computing Surveys (CSUR)},
	author = {Mehrabi, Ninareh and Morstatter, Fred and Saxena, Nripsuta and Lerman, Kristina and Galstyan, Aram},
	year = {2021},
	pages = {1--35},
}

@article{haibe-kains_transparency_2020,
	title = {Transparency and reproducibility in artificial intelligence},
	volume = {586},
	doi = {10.1038/s41586-020-2766-y},
	number = {7829},
	journal = {Nature},
	author = {Haibe-Kains, Benjamin and Adam, Geoffrey A and Hosny, Ahmed and Khodakarami, Fatemeh and Waldron, Levi and Wang, Bin and McIntosh, Chris and Goldenberg, Anna and Kundaje, Anshul and Greene, Casey S and {others}},
	year = {2020},
	pages = {E14--E16},
}

@article{chen_transunet_2021,
	title = {{TransUNet}: {Transformers} make strong encoders for medical image segmentation},
	doi = {10.48550/arXiv.2102.04306},
	journal = {arXiv preprint arXiv:2102.04306},
	author = {Chen, Jieneng and Lu, Yongyi and Yu, Qihang and Luo, Tongda and Adeli, Ehsan and Wang, Yan and Lu, Le and Zhou, Yuyin and Feng, Xiaohui},
	year = {2021},
}

@article{hatamizadeh_unetr_2022,
	title = {{UNETR}: {Transformers} for {3D} medical image segmentation},
	doi = {10.1109/WACV51458.2022.00065},
	journal = {Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
	author = {Hatamizadeh, Ali and Yin, Hongxu and Kautz, Jan and Molchanov, Pavlo},
	year = {2022},
	pages = {574--584},
}

@book{higgins_cochrane_2022,
	edition = {Version 6.3 (updated February 2022)},
	title = {Cochrane {Handbook} for {Systematic} {Reviews} of {Interventions}},
	isbn = {978-1-119-53660-4},
	publisher = {Cochrane},
	editor = {Higgins, Julian PT and Thomas, James and Chandler, Jacqueline and Cumpston, Miranda and Li, Tianjing and Page, Matthew J and Welch, Vivian A},
	year = {2022},
}

@book{borenstein_introduction_2009,
	title = {Introduction to {Meta}-{Analysis}},
	isbn = {978-0-470-05724-7},
	publisher = {John Wiley \& Sons},
	author = {Borenstein, Michael and Hedges, Larry V and Higgins, Julian PT and Rothstein, Hannah R},
	year = {2009},
	doi = {10.1002/9780470743386},
}

@book{topol_deep_2019,
	title = {Deep {Medicine}: {How} {Artificial} {Intelligence} {Can} {Make} {Healthcare} {Human} {Again}},
	publisher = {Basic Books},
	author = {Topol, Eric},
	year = {2019},
}

@misc{parsifal_ltd_parsifal_2018,
	title = {Parsifal: {A} {Web}-based {Tool} to {Support} {Systematic} {Literature} {Reviews}},
	url = {https://parsif.al/},
	author = {{Parsifal Ltd.}},
	year = {2018},
}

@article{pizzol_alise_2015,
	title = {{ANÁLISE} {BIBLIOMÉTRICA} {DA} {PRODUÇÃO} {CIENTÍFICA} {SOBRE} {LINKED} {DATA}},
	volume = {20},
	language = {pt},
	number = {3},
	author = {Pizzol, Leandro Dal and Speroni, Rafael de Moura and Zancanaro, Airton and Gauthier, Fernando Ostuni and Todesco, José Leomar},
	year = {2015},
	file = {Pizzol et al. - ANÁLISE BIBLIOMÉTRICA DA PRODUÇÃO CIENTÍFICA SOBRE.pdf:C\:\\Users\\Wellerson\\Zotero\\storage\\MZ8ZR3VY\\Pizzol et al. - ANÁLISE BIBLIOMÉTRICA DA PRODUÇÃO CIENTÍFICA SOBRE.pdf:application/pdf},
}

@article{sampson_evidence-based_2009,
	title = {An evidence-based practice guideline for the peer review of electronic search strategies},
	volume = {62},
	copyright = {https://www.elsevier.com/tdm/userlicense/1.0/},
	issn = {08954356},
	doi = {10.1016/j.jclinepi.2008.10.012},
	language = {pt},
	number = {9},
	urldate = {2024-06-30},
	journal = {Journal of Clinical Epidemiology},
	author = {Sampson, Margaret and McGowan, Jessie and Cogo, Elise and Grimshaw, Jeremy and Moher, David and Lefebvre, Carol},
	month = sep,
	year = {2009},
	pages = {944--952},
	file = {Sampson et al. - 2009 - An evidence-based practice guideline for the peer .pdf:C\:\\Users\\Wellerson\\Zotero\\storage\\S9T9WKSV\\Sampson et al. - 2009 - An evidence-based practice guideline for the peer .pdf:application/pdf},
}

@article{de_sousa_pesquisa_2021,
	title = {A {PESQUISA} {BIBLIOGRÁFICA}: {PRINCÍPIOS} {E} {FUNDAMENTOS}},
	abstract = {The main objective of this paper is to analyze and describe the principles and fundamentals that characterize the development of a Bibliographical Research. In the text, concepts, definitions, characteristics and procedures are presented, from the perspective of different authors, that allow the adequate understanding of a research that is structured and developed from the theoretical production of other authors.},
	language = {pt},
	journal = {A. S.},
	author = {de Sousa, Angélica Silva and de Oliveira, Guilherme Saramago and Alves, Laís Hilário},
	year = {2021},
	file = {de Sousa et al. - A PESQUISA BIBLIOGRÁFICA PRINCÍPIOS E FUNDAMENTOS.pdf:C\:\\Users\\Wellerson\\Zotero\\storage\\T7UCLYA6\\de Sousa et al. - A PESQUISA BIBLIOGRÁFICA PRINCÍPIOS E FUNDAMENTOS.pdf:application/pdf},
}

@article{paixao_machine_2022,
	title = {Machine {Learning} na {Medicina}: {Revisão} e {Aplicabilidade}},
	volume = {118},
	issn = {0066-782X, 1678-4170},
	shorttitle = {Machine {Learning} na {Medicina}},
	doi = {10.36660/abc.20200596},
	language = {pt},
	number = {1},
	urldate = {2024-10-10},
	journal = {Arquivos Brasileiros de Cardiologia},
	author = {Paixão, Gabriela Miana De Mattos and Santos, Bruno Campos and Araujo, Rodrigo Martins De and Ribeiro, Manoel Horta and Moraes, Jermana Lopes De and Ribeiro, Antonio L.},
	month = jan,
	year = {2022},
	pages = {95--102},
	file = {Paixão et al. - 2022 - Machine Learning na Medicina Revisão e Aplicabili.pdf:C\:\\Users\\Wellerson\\Zotero\\storage\\DINU8BA8\\Paixão et al. - 2022 - Machine Learning na Medicina Revisão e Aplicabili.pdf:application/pdf},
}

@article{oliveira_medicina_2025,
	title = {{MEDICINA} {DE} {PRECISÃO}: {SISTEMA} {DE} {GERENCIAMENTO} {E} {CONTROLE} {DE} {DADOS} {RETROALIMENTÁVEIS} {PARA} {O} {APRIMORAMENTO} {DO} {DESENVOLVIMENTO} {DE} {ALGORITMOS} {DE} {MACHINE} {LEARNING} {NO} {BRASIL}},
	volume = {18},
	copyright = {https://creativecommons.org/licenses/by-nc/4.0},
	issn = {1981-223X},
	shorttitle = {{MEDICINA} {DE} {PRECISÃO}},
	doi = {10.54751/revistafoco.v18n2-144},
	abstract = {A pesquisa visa o desenvolvimento de um sistema inovador para os setores de Computação e Saúde. Projetado para otimizar processos e favorecer o desenvolvimento de algoritmos de machine learning aplicados na medicina, ele alia formas de se resolver alguns paradigmas da computação e de diversas Entidades com ou sem fins lucrativos, seja em aspectos de regulamentação ou de avaliação qualitativa da ciência. A partir de recursos integrados e métodos de operação responsáveis, o sistema propõe o compartilhamento de tecnologias e pesquisas de qualidade. O foco está no aprimoramento das bases de dados do país a fim de fornecer um ambiente confiável, unificando-as. Além disso, o sistema visa incentivar práticas éticas e responsáveis ao longo de sua utilização, incluindo suporte técnico eficiente. Um sistema simples, inclusivo e confiável que permitirá a criação de ambientes de pesquisas virtuais entre pesquisadores de todo o país. Com características únicas e benefícios claros, o sistema surge como uma solução viável e inovadora para a regulamentação e expansão do desenvolvimento das IA’s.},
	number = {2},
	urldate = {2025-04-03},
	journal = {REVISTA FOCO},
	author = {Oliveira, Wellerson Henrique Araújo},
	month = feb,
	year = {2025},
	pages = {e7861},
	file = {Full Text PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\KGU6K6UA\\Oliveira - 2025 - MEDICINA DE PRECISÃO SISTEMA DE GERENCIAMENTO E CONTROLE DE DADOS RETROALIMENTÁVEIS PARA O APRIMORA.pdf:application/pdf},
}

@article{santos_artificial_2019,
	title = {Artificial intelligence, machine learning, computer-aided diagnosis, and radiomics: advances in imaging towards to precision medicine},
	volume = {52},
	copyright = {http://creativecommons.org/licenses/by/4.0/},
	issn = {1678-7099},
	shorttitle = {Artificial intelligence, machine learning, computer-aided diagnosis, and radiomics},
	doi = {10.1590/0100-3984.2019.0049},
	abstract = {Abstract The discipline of radiology and diagnostic imaging has evolved greatly in recent years. We have observed an exponential increase in the number of exams performed, subspecialization of medical fields, and increases in accuracy of the various imaging methods, making it a challenge for the radiologist to “know everything about all exams and regions”. In addition, imaging exams are no longer only qualitative and diagnostic, providing now quantitative information on disease severity, as well as identifying biomarkers of prognosis and treatment response. In view of this, computer-aided diagnosis systems have been developed with the objective of complementing diagnostic imaging and helping the therapeutic decision-making process. With the advent of artificial intelligence, “big data”, and machine learning, we are moving toward the rapid expansion of the use of these tools in daily life of physicians, making each patient unique, as well as leading radiology toward the concept of multidisciplinary approach and precision medicine. In this article, we will present the main aspects of the computational tools currently available for analysis of images and the principles of such analysis, together with the main terms and concepts involved, as well as examining the impact that the development of artificial intelligence has had on radiology and diagnostic imaging. , Resumo A disciplina de radiologia e diagnóstico por imagem evoluiu sobremaneira nos últimos anos. Temos observado o aumento exponencial do número de exames realizados, a subespecialização das disciplinas médicas e a maior acurácia dos métodos, tornando um desafio para o médico radiologista “saber tudo sobre todos exames e regiões”. Além disso, os exames de imagem deixaram de ser somente qualitativos e diagnósticos e passaram a fornecer informações quantitativas e de gravidade de doença, identificando biomarcadores prognósticos e de resposta ao tratamento. Diante disso, sistemas computadorizados de auxílio diagnóstico vêm sendo desenvolvidos com o objetivo dar suporte ao diagnóstico por imagem e à decisão terapêutica. Com o advento da inteligência artificial, do big data e do aprendizado de máquina, caminhamos para a rápida expansão do uso dessas ferramentas no dia-a-dia dos médicos, tornando cada paciente único, levando a radiologia ao encontro do conceito de abordagem multidisciplinar e medicina de precisão. Neste artigo serão abordados os principais aspectos das ferramentas computacionais atualmente disponíveis para análise das imagens médicas, apresentando os princípios de análise das imagens, os principais termos e conceitos envolvidos nesses processos, assim como o impacto do desenvolvimento da inteligência artificial na radiologia e diagnóstico por imagem.},
	number = {6},
	urldate = {2025-04-03},
	journal = {Radiologia Brasileira},
	author = {Santos, Marcel Koenigkam and Ferreira Júnior, José Raniery and Wada, Danilo Tadao and Tenório, Ariane Priscilla Magalhães and Nogueira-Barbosa, Marcello Henrique and Marques, Paulo Mazzoncini De Azevedo},
	month = dec,
	year = {2019},
	pages = {387--396},
	file = {Texto completo:C\:\\Users\\Wellerson\\Zotero\\storage\\NL7ZS3LX\\Santos et al. - 2019 - Artificial intelligence, machine learning, computer-aided diagnosis, and radiomics advances in imag.pdf:application/pdf},
}

@article{costa_importancia_2014,
	title = {A {Importância} da {Utilização} do {Software} na Área da {Saúde}},
	abstract = {This paper aims to emphasize by means of literature and quantitative the importance of software in healthcare Guarapuava City, emphasizing the benefits over the years. The development of new technology has helped health in many ways, IT is now incorporated within the health institutions and is making the daily lives of professionals, institutions and patients more dynamic, safe, with higher quality and lower costs. With the aid of field research identified the importance that the software has within healthcare institutions as well as for professionals who use it to perform patient care. In this respect it is evident that some of the advances made in the area of Health has the contribution of Information Technology.},
	language = {pt},
	author = {Costa, Karine Campos and Orlovski, Regiane},
	year = {2014},
	file = {PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\M98888B7\\Costa e Orlovski - A Importância da Utilização do Software na Área da Saúde.pdf:application/pdf},
}

@article{santana_rs-fmri_2022,
	title = {rs-{fMRI} and machine learning for {ASD} diagnosis: a systematic review and meta-analysis},
	volume = {12},
	issn = {2045-2322},
	shorttitle = {rs-{fMRI} and machine learning for {ASD} diagnosis},
	doi = {10.1038/s41598-022-09821-6},
	abstract = {Abstract Autism Spectrum Disorder (ASD) diagnosis is still based on behavioral criteria through a lengthy and time-consuming process. Much effort is being made to identify brain imaging biomarkers and develop tools that could facilitate its diagnosis. In particular, using Machine Learning classifiers based on resting-state fMRI (rs-fMRI) data is promising, but there is an ongoing need for further research on their accuracy and reliability. Therefore, we conducted a systematic review and meta-analysis to summarize the available evidence in the literature so far. A bivariate random-effects meta-analytic model was implemented to investigate the sensitivity and specificity across the 55 studies that offered sufficient information for quantitative analysis. Our results indicated overall summary sensitivity and specificity estimates of 73.8\% and 74.8\%, respectively. SVM stood out as the most used classifier, presenting summary estimates above 76\%. Studies with bigger samples tended to obtain worse accuracies, except in the subgroup analysis for ANN classifiers. The use of other brain imaging or phenotypic data to complement rs-fMRI information seems promising, achieving higher sensitivities when compared to rs-fMRI data alone (84.7\% versus 72.8\%). Finally, our analysis showed AUC values between acceptable and excellent. Still, given the many limitations indicated in our study, further well-designed studies are warranted to extend the potential use of those classification algorithms to clinical settings.},
	language = {en},
	number = {1},
	urldate = {2025-04-04},
	journal = {Scientific Reports},
	author = {Santana, Caio Pinheiro and De Carvalho, Emerson Assis and Rodrigues, Igor Duarte and Bastos, Guilherme Sousa and De Souza, Adler Diniz and De Brito, Lucelmo Lacerda},
	month = apr,
	year = {2022},
	pages = {6030},
	file = {PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\KFQANTFG\\Santana et al. - 2022 - rs-fMRI and machine learning for ASD diagnosis a systematic review and meta-analysis.pdf:application/pdf},
}

@article{higgins_measuring_2003,
	title = {Measuring inconsistency in meta-analyses},
	volume = {327},
	issn = {0959-8138, 1468-5833},
	url = {https://www.bmj.com/lookup/doi/10.1136/bmj.327.7414.557},
	doi = {10.1136/bmj.327.7414.557},
	language = {en},
	number = {7414},
	urldate = {2025-05-15},
	journal = {BMJ},
	author = {Higgins, J. P T},
	month = sep,
	year = {2003},
	pages = {557--560},
	file = {PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\L2VXPWVF\\Higgins - 2003 - Measuring inconsistency in meta-analyses.pdf:application/pdf},
}

@article{wang_guidelines_2023,
	title = {Guidelines, {Consensus} {Statements}, and {Standards} for the {Use} of {Artificial} {Intelligence} in {Medicine}: {Systematic} {Review}},
	volume = {25},
	issn = {1438-8871},
	shorttitle = {Guidelines, {Consensus} {Statements}, and {Standards} for the {Use} of {Artificial} {Intelligence} in {Medicine}},
	url = {https://www.jmir.org/2023/1/e46089},
	doi = {10.2196/46089},
	abstract = {Background: The application of artificial intelligence (AI) in the delivery of health care is a promising area, and guidelines, consensus statements, and standards on AI regarding various topics have been developed. Objective: We performed this study to assess the quality of guidelines, consensus statements, and standards in the field of AI for medicine and to provide a foundation for recommendations about the future development of AI guidelines. Methods: We searched 7 electronic databases from database establishment to April 6, 2022, and screened articles involving AI guidelines, consensus statements, and standards for eligibility. The AGREE II (Appraisal of Guidelines for Research \& Evaluation II) and RIGHT (Reporting Items for Practice Guidelines in Healthcare) tools were used to assess the methodological and reporting quality of the included articles. Results: This systematic review included 19 guideline articles, 14 consensus statement articles, and 3 standard articles published between 2019 and 2022. Their content involved disease screening, diagnosis, and treatment; AI intervention trial reporting; AI imaging development and collaboration; AI data application; and AI ethics governance and applications. Our quality assessment revealed that the average overall AGREE II score was 4.0 (range 2.2-5.5; 7-point Likert scale) and the mean overall reporting rate of the RIGHT tool was 49.4\% (range 25.7\%-77.1\%). Conclusions: The results indicated important differences in the quality of different AI guidelines, consensus statements, and standards. We made recommendations for improving their methodological and reporting quality. Trial Registration: PROSPERO International Prospective Register of Systematic Reviews (CRD42022321360); https://www.crd.york.ac.uk/prospero/display\_record.php?RecordID=321360},
	language = {en},
	urldate = {2025-05-16},
	journal = {Journal of Medical Internet Research},
	author = {Wang, Ying and Li, Nian and Chen, Lingmin and Wu, Miaomiao and Meng, Sha and Dai, Zelei and Zhang, Yonggang and Clarke, Mike},
	month = nov,
	year = {2023},
	pages = {e46089},
	file = {PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\2XI6D997\\Wang et al. - 2023 - Guidelines, Consensus Statements, and Standards for the Use of Artificial Intelligence in Medicine.pdf:application/pdf},
}

@article{al_mansour_mammovit_2025,
	title = {{MammoViT}: {A} {Custom} {Vision} {Transformer} {Architecture} for {Accurate} {BIRADS} {Classification} in {Mammogram} {Analysis}},
	volume = {15},
	copyright = {https://creativecommons.org/licenses/by/4.0/},
	issn = {2075-4418},
	shorttitle = {{MammoViT}},
	url = {https://www.mdpi.com/2075-4418/15/3/285},
	doi = {10.3390/diagnostics15030285},
	abstract = {Background: Breast cancer screening through mammography interpretation is crucial for early detection and improved patient outcomes. However, the manual classification of mammograms using the BIRADS (Breast Imaging-Reporting and Data System) remains challenging due to subtle imaging features, inter-reader variability, and increasing radiologist workload. Traditional computer-aided detection systems often struggle with complex feature extraction and contextual understanding of mammographic abnormalities. To address these limitations, this study proposes MammoViT, a novel hybrid deep learning framework that leverages both ResNet50’s hierarchical feature extraction capabilities and Vision Transformer’s ability to capture long-range dependencies in images. Methods: We implemented a multi-stage approach utilizing a pre-trained ResNet50 model for initial feature extraction from mammogram images. To address the significant class imbalance in our four-class BIRADS dataset, we applied SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic samples for minority classes. The extracted feature arrays were transformed into non-overlapping patches with positional encodings for Vision Transformer processing. The Vision Transformer employs multi-head self-attention mechanisms to capture both local and global relationships between image patches, with each attention head learning different aspects of spatial dependencies. The model was optimized using Keras Tuner and trained using 5-fold cross-validation with early stopping to prevent overfitting. Results: MammoViT achieved 97.4\% accuracy in classifying mammogram images across different BIRADS categories. The model’s effectiveness was validated through comprehensive evaluation metrics, including a classification report, confusion matrix, probability distribution, and comparison with existing studies. Conclusions: MammoViT effectively combines ResNet50 and Vision Transformer architectures while addressing the challenge of imbalanced medical imaging datasets. The high accuracy and robust performance demonstrate its potential as a reliable tool for supporting clinical decision-making in breast cancer screening.},
	language = {en},
	number = {3},
	urldate = {2025-05-16},
	journal = {Diagnostics},
	author = {Al Mansour, Abdullah G. M. and Alshomrani, Faisal and Alfahaid, Abdullah and Almutairi, Abdulaziz T. M.},
	month = jan,
	year = {2025},
	pages = {285},
	file = {Full Text PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\MG8M4AGY\\Al Mansour et al. - 2025 - MammoViT A Custom Vision Transformer Architecture for Accurate BIRADS Classification in Mammogram A.pdf:application/pdf},
}

@article{takahashi_comparison_2024,
	title = {Comparison of {Vision} {Transformers} and {Convolutional} {Neural} {Networks} in {Medical} {Image} {Analysis}: {A} {Systematic} {Review}},
	volume = {48},
	issn = {1573-689X},
	shorttitle = {Comparison of {Vision} {Transformers} and {Convolutional} {Neural} {Networks} in {Medical} {Image} {Analysis}},
	url = {https://link.springer.com/10.1007/s10916-024-02105-8},
	doi = {10.1007/s10916-024-02105-8},
	abstract = {In the rapidly evolving field of medical image analysis utilizing artificial intelligence (AI), the selection of appropriate computational models is critical for accurate diagnosis and patient care. This literature review provides a comprehensive comparison of vision transformers (ViTs) and convolutional neural networks (CNNs), the two leading techniques in the field of deep learning in medical imaging. We conducted a survey systematically. Particular attention was given to the robustness, computational efficiency, scalability, and accuracy of these models in handling complex medical datasets. The review incorporates findings from 36 studies and indicates a collective trend that transformer-based models, particularly ViTs, exhibit significant potential in diverse medical imaging tasks, showcasing superior performance when contrasted with conventional CNN models. Additionally, it is evident that pre-training is important for transformer applications. We expect this work to help researchers and practitioners select the most appropriate model for specific medical image analysis tasks, accounting for the current state of the art and future trends in the field.},
	language = {en},
	number = {1},
	urldate = {2025-05-13},
	journal = {Journal of Medical Systems},
	author = {Takahashi, Satoshi and Sakaguchi, Yusuke and Kouno, Nobuji and Takasawa, Ken and Ishizu, Kenichi and Akagi, Yu and Aoyama, Rina and Teraya, Naoki and Bolatkan, Amina and Shinkai, Norio and Machino, Hidenori and Kobayashi, Kazuma and Asada, Ken and Komatsu, Masaaki and Kaneko, Syuzo and Sugiyama, Masashi and Hamamoto, Ryuji},
	month = sep,
	year = {2024},
	pages = {84},
	file = {PDF:C\:\\Users\\Wellerson\\Zotero\\storage\\FGJLT6CZ\\Takahashi et al. - 2024 - Comparison of Vision Transformers and Convolutional Neural Networks in Medical Image Analysis A Sys.pdf:application/pdf},
}
